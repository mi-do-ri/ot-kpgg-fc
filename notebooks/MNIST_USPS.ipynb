{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f:\\DS Lab\\OT\\ot-kpgg-fc\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "# OT\n",
    "import ot\n",
    "from optimal_transport.models import KeypointFOT, FOT, LOT, EMD\n",
    "from typing import Tuple, Optional, List, Union, Dict\n",
    "\n",
    "# Torch imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.nn as nn\n",
    "\n",
    "# To make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Load MNIST\n",
    "def mnist(\n",
    "    root_dir=\"datasets\", n_samples=1000,\n",
    "    transform=transforms.Compose([transforms.ToTensor()]), seed=5\n",
    "):\n",
    "    torch.manual_seed(5)\n",
    "\n",
    "    train_dataset = datasets.MNIST(root=os.path.join(root_dir, \"mnist\"), train=True, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=n_samples, shuffle=True)\n",
    "    test_dataset = datasets.MNIST(root=os.path.join(root_dir, \"mnist\"), train=False, download=True, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=2*n_samples, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "mnist_train_loader, mnist_test_loader = mnist(n_samples=1000)\n",
    "mnist_X_train, mnist_y_train = next(iter(mnist_train_loader))\n",
    "mnist_X_test, mnist_y_test = next(iter(mnist_test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Load USPS\n",
    "def usps(\n",
    "    root_dir=\"datasets\", n_samples=1000,\n",
    "    transform=transforms.Compose([transforms.ToTensor(), transforms.Pad(6)]), seed=5,\n",
    "):\n",
    "    torch.manual_seed(5)\n",
    "\n",
    "    train_dataset = datasets.USPS(root=os.path.join(root_dir, \"usps\"), train=True, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=n_samples, shuffle=True)\n",
    "    test_data = datasets.USPS(root=os.path.join(root_dir, \"usps\"), train=False, download=True, transform=transform)\n",
    "    test_loader = DataLoader(test_data, batch_size=2*n_samples, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "usps_train_loader, usps_test_loader = usps(n_samples=1000)\n",
    "usps_X_train, usps_y_train = next(iter(usps_train_loader))\n",
    "usps_X_test, usps_y_test = next(iter(usps_test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Load pretrained\n",
    "model_urls = {\n",
    "    'mnist': 'http://ml.cs.tsinghua.edu.cn/~chenxi/pytorch-models/mnist-b07bb66b.pth'\n",
    "}\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dims, n_hiddens, n_class):\n",
    "        super(MLP, self).__init__()\n",
    "        assert isinstance(input_dims, int), 'Please provide int for input_dims'\n",
    "        self.input_dims = input_dims\n",
    "        current_dims = input_dims\n",
    "        layers = OrderedDict()\n",
    "\n",
    "        if isinstance(n_hiddens, int):\n",
    "            n_hiddens = [n_hiddens]\n",
    "        else:\n",
    "            n_hiddens = list(n_hiddens)\n",
    "        for i, n_hidden in enumerate(n_hiddens):\n",
    "            layers['fc{}'.format(i+1)] = nn.Linear(current_dims, n_hidden)\n",
    "            layers['relu{}'.format(i+1)] = nn.ReLU()\n",
    "            layers['drop{}'.format(i+1)] = nn.Dropout(0.2)\n",
    "            current_dims = n_hidden\n",
    "        layers['out'] = nn.Linear(current_dims, n_class)\n",
    "\n",
    "        self.model= nn.Sequential(layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.view(input.size(0), -1)\n",
    "        assert input.size(1) == self.input_dims\n",
    "        return self.model.forward(input)\n",
    "\n",
    "def pretrain_mnist(input_dims=784, n_hiddens=[256, 256], n_class=10, pretrained=None):\n",
    "    model = MLP(input_dims, n_hiddens, n_class)\n",
    "    if pretrained is not None:\n",
    "        m = model_zoo.load_url(model_urls['mnist'],map_location=torch.device('cpu'))\n",
    "        state_dict = m.state_dict() if isinstance(m, nn.Module) else m\n",
    "        assert isinstance(state_dict, (dict, OrderedDict)), type(state_dict)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "m = pretrain_mnist(pretrained=True).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Metrics\n",
    "def accuracy(y_hat, y):\n",
    "    y_pred = np.argmax(y_hat, axis=1)\n",
    "    acc = (y_pred == y).sum() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Keypoints\n",
    "def query_keypoints(X, y, keypoints_per_cls=1):\n",
    "    def euclidean(source, target, p=2):\n",
    "        return np.sum(\n",
    "            np.power(\n",
    "                source.reshape([source.shape[0], 1, source.shape[1]]) -\n",
    "                target.reshape([1, target.shape[0], target.shape[1]]),\n",
    "                p\n",
    "            ),\n",
    "            axis=-1\n",
    "        ) ** 1/2\n",
    "    labels = np.unique(y)\n",
    "    selected_inds = []\n",
    "    for label in labels:\n",
    "        cls_indices = np.where(y == label)[0]\n",
    "        distance = euclidean(X[cls_indices], np.mean(X[cls_indices], axis=0)[None, :]).squeeze()\n",
    "        selected_inds.extend(cls_indices[np.argsort(distance)[:keypoints_per_cls]])\n",
    "    return selected_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MNIST ---\n",
      "Train accuracy: 0.993\n",
      "Test accuracy : 0.9705\n",
      "--- USPS ---\n",
      "Train accuracy: 0.869\n",
      "Test accuracy : 0.802\n"
     ]
    }
   ],
   "source": [
    "#@title Before mapping\n",
    "print(\"--- MNIST ---\")\n",
    "print('Train accuracy:', accuracy(m(mnist_X_train).detach().numpy(), mnist_y_train.numpy()))\n",
    "print('Test accuracy :', accuracy(m(mnist_X_test).detach().numpy(), mnist_y_test.numpy()))\n",
    "print(\"--- USPS ---\")\n",
    "print('Train accuracy:', accuracy(m(usps_X_train).detach().numpy(), usps_y_train.numpy()))\n",
    "print('Test accuracy :', accuracy(m(usps_X_test).detach().numpy(), usps_y_test.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Project samples into logit space\n",
    "mnist_train_logits = np.array(m(mnist_X_train).detach())\n",
    "usps_test_logits = np.array(m(usps_X_test).detach())\n",
    "mnist_train_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1843, 201),\n",
       " (1747, 953),\n",
       " (240, 439),\n",
       " (1278, 607),\n",
       " (1464, 137),\n",
       " (351, 904),\n",
       " (1822, 314),\n",
       " (196, 334),\n",
       " (717, 581),\n",
       " (1438, 479)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Extract candidate keypoints\n",
    "mnist_keypoints = query_keypoints(mnist_train_logits, mnist_y_train.numpy())\n",
    "usps_keypoints = query_keypoints(usps_test_logits, usps_y_test.numpy())\n",
    "K = [(usps_keypoints[i], mnist_keypoints[i]) for i in range(len(mnist_keypoints))]\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold reached at iteration 1\n",
      ">> [KeypointFOT] Acc: 0.8255\n",
      ">> [FOT] Acc: 0.762\n",
      ">> [LOT] Acc: 0.811\n",
      ">> [OT] Acc: 0.7655\n"
     ]
    }
   ],
   "source": [
    "#@title Domain adaptation\n",
    "n_anchors = 10\n",
    "model = {\n",
    "    \"KeypointFOT\": KeypointFOT(mnist_y_train, n_free_anchors=n_anchors, alpha=0.5, stop_thr=1e-5,\n",
    "                               sinkhorn_reg=0.001, temperature=0.1, div_term=1e-20, max_iters=200, n_clusters = 10),\n",
    "    \"FOT\": FOT(n_anchors=n_anchors, sinkhorn_reg=0.1),\n",
    "    \"LOT\": LOT(None, n_source_anchors=n_anchors, n_target_anchors=n_anchors, epsilon=10, epsilon_z=10),\n",
    "    \"OT\": EMD(),\n",
    "}\n",
    "\n",
    "exp_name = \"domain_adaptation\"\n",
    "record_ = {}\n",
    "record_[exp_name] = {model_id: {\"accuracy\": []} for model_id in model}\n",
    "\n",
    "n = usps_test_logits.shape[0]\n",
    "n_ = mnist_train_logits.shape[0]\n",
    "for model_id in model:\n",
    "    model[model_id].fit(usps_test_logits, mnist_train_logits,\n",
    "                        a=1/n*np.ones(n), b=1/n_*np.ones(n_), K=K)\n",
    "    transported_logits = model[model_id].transport(usps_test_logits, mnist_train_logits)\n",
    "\n",
    "    record_[exp_name][model_id][\"accuracy\"].append(accuracy(transported_logits, usps_y_test.numpy()))\n",
    "    score = record_[exp_name][model_id][\"accuracy\"][0]\n",
    "    print(f\">> [{model_id}] Acc: {score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
